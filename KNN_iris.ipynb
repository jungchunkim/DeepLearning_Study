{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iris 데이터를 사용하여 KNN 알고리즘을 직접 작성해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris=load_iris()\n",
    "X=iris.data #data size 150개 (feature 4개)\n",
    "y=iris.target # 결과 값 ( 어떤 꽃 종류인지 0 ,1 ,2 중에 있다.)\n",
    "y_name=iris.target_names\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유클리디안 거리를 이용한 거리 구하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2, 1, 60, 139, 0])\n",
    "b = np.array([3, 2, 80, 148, 0])\n",
    "\n",
    "def euclidean_distance(x, y):   \n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 거리와 index k개반환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbors(x, iris_data, k): \n",
    "    \n",
    "    distance_iris = np.zeros(len(iris_data))\n",
    "    # 거리를 data와 비교해서 각각 구한다.\n",
    "    for i in  range(len(iris_data)):\n",
    "        distance_iris[i] = euclidean_distance(iris_data[i],x )\n",
    "    # index (반환 거리가 작은 순으로 정렬- k개를 뽑는다)    \n",
    "    sorted_index = np.argsort(distance_iris)[:k]  \n",
    "    \n",
    "    sorted_distance=np.sort(distance_iris)[:k]\n",
    "        \n",
    "    return sorted_index,sorted_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149 127 138 142 101]\n",
      "[0.         0.28284271 0.31622777 0.33166248 0.33166248]\n"
     ]
    }
   ],
   "source": [
    "sorted_a, sorted_b = find_nearest_neighbors(X[149], X, 5)\n",
    "print(sorted_a)\n",
    "print(sorted_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# majority vote를 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority_vote(sorted_index,k,y):\n",
    "    \n",
    "    target_result = np.zeros(k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        target_result[i] = y[sorted_index[i]]\n",
    "    \n",
    "    num_cnt=Counter(target_result)\n",
    "    # 제일 많이 있는 것 return 한다.\n",
    "    max_cnt = -1\n",
    "    for num in num_cnt:\n",
    "        if num_cnt[num] > max_cnt:\n",
    "            max_cnt=num_cnt[num]\n",
    "            max_result=int(num)\n",
    "\n",
    "    return max_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_vote(sorted_a,5,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weighted vote를 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_majority_vote(sorted_index,sorted_distance,k,y):\n",
    "    iris_sum = np.zeros(3)\n",
    "    for i in range(k):\n",
    "        # weight를 거리의 역수로 생각하자\n",
    "        iris_sum[y[sorted_index[i]]]+=1/sorted_distance[i]\n",
    "    max_iris=-1\n",
    "    for i in range(3):\n",
    "        if iris_sum[i]>max_iris:\n",
    "            max_iris=iris_sum[i]\n",
    "            max_result=i\n",
    "            \n",
    "    return max_result  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_a, sorted_b = find_nearest_neighbors(X[146], X[:145], 5)\n",
    "weighted_majority_vote(sorted_a,sorted_b,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN 결과값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris=load_iris()\n",
    "X=iris.data #data size 150개 (feature 4개)\n",
    "y=iris.target # 결과 값 ( 어떤 꽃 종류인지 0 ,1 ,2 중에 있다.)\n",
    "y_name=iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=14\n",
    "#test data, train data 분리\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "for i in range(len(X)):\n",
    "    if i==num:\n",
    "        X_test.append(X[i])\n",
    "        num+=15\n",
    "    else:\n",
    "        X_train.append(X[i])\n",
    "\n",
    "num=14\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "for i in range(len(y)):\n",
    "    if i==num:\n",
    "        y_test.append(y[i])\n",
    "        num+=15\n",
    "    else:\n",
    "        y_train.append(y[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN class 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN_class:\n",
    "    def __init__(self,X_train,y_train):\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "        \n",
    "    def euclidean_distance(self,a, b):\n",
    "        # 유클리드 거리 방식을 사용하였다.\n",
    "        return np.sqrt(np.sum((a - b) ** 2))\n",
    "    \n",
    "    def find_nearest_neighbors(self, x, k): \n",
    "        \n",
    "        distance_iris = np.zeros(len(self.X_train))\n",
    "        # 거리를 data와 비교해서 각각 구한다.\n",
    "        for i in  range(len(self.X_train)):\n",
    "            distance_iris[i] = self.euclidean_distance(self.X_train[i],x )\n",
    "        # index (반환 거리가 작은 순으로 정렬- k개를 뽑는다)    \n",
    "        sorted_index = np.argsort(distance_iris)[:k]  \n",
    "    \n",
    "        sorted_distance=np.sort(distance_iris)[:k]\n",
    "        \n",
    "        return sorted_index,sorted_distance\n",
    "    \n",
    "    def majority_vote(self, sorted_index, k):\n",
    "        \n",
    "        target_result = np.zeros(k)\n",
    "    \n",
    "        for i in range(k):\n",
    "            target_result[i] = self.y_train[sorted_index[i]]\n",
    "        \n",
    "        iris_sum=np.zeros(3)\n",
    "        for i in range(k):\n",
    "            #가까운 것의 개수를 배열에 넣는다. (나올때마다 추가)\n",
    "            iris_sum[int(target_result[i])]+=1\n",
    "        \n",
    "        # 제일 가까이 있는 것의 index를 return 한다.\n",
    "        max_iris=-1\n",
    "        for i in range(3):\n",
    "            if iris_sum[i]>max_iris:\n",
    "                max_iris=iris_sum[i]\n",
    "                max_result=i\n",
    "\n",
    "        return max_result\n",
    "    \n",
    "    def weighted_majority_vote(self, sorted_index,sorted_distance,k):\n",
    "        iris_sum = np.zeros(3)\n",
    "        for i in range(k):\n",
    "            # weight를 거리의 역수로 생각하자\n",
    "            iris_sum[self.y_train[sorted_index[i]]]+=1/sorted_distance[i]\n",
    "            \n",
    "        max_iris=-1\n",
    "        for i in range(3):\n",
    "            if iris_sum[i]>max_iris:\n",
    "                max_iris=iris_sum[i]\n",
    "                max_result=i\n",
    "            \n",
    "        return max_result \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================== k is 3 ==========================\n",
      "====================== majority vote ======================\n",
      "Test Data index:  0 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  1 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  2 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  3 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  4 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  5 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  6 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  7 Computed class:  versicolor , True class:  virginica\n",
      "Test Data index:  8 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  9 Computed class:  virginica , True class:  virginica\n",
      "majority vote k = 3 , Accuracy : 0.9\n",
      "=================== weighted majority vote ===================\n",
      "Test Data index:  0 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  1 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  2 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  3 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  4 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  5 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  6 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  7 Computed class:  versicolor , True class:  virginica\n",
      "Test Data index:  8 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  9 Computed class:  virginica , True class:  virginica\n",
      "weighted majority vote k = 3 , Accuracy : 0.9\n",
      "========================== k is 5 ==========================\n",
      "====================== majority vote ======================\n",
      "Test Data index:  0 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  1 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  2 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  3 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  4 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  5 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  6 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  7 Computed class:  versicolor , True class:  virginica\n",
      "Test Data index:  8 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  9 Computed class:  virginica , True class:  virginica\n",
      "majority vote k = 5 , Accuracy : 0.9\n",
      "=================== weighted majority vote ===================\n",
      "Test Data index:  0 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  1 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  2 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  3 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  4 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  5 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  6 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  7 Computed class:  versicolor , True class:  virginica\n",
      "Test Data index:  8 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  9 Computed class:  virginica , True class:  virginica\n",
      "weighted majority vote k = 5 , Accuracy : 0.9\n",
      "========================== k is 10 ==========================\n",
      "====================== majority vote ======================\n",
      "Test Data index:  0 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  1 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  2 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  3 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  4 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  5 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  6 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  7 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  8 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  9 Computed class:  virginica , True class:  virginica\n",
      "majority vote k = 10 , Accuracy : 1.0\n",
      "=================== weighted majority vote ===================\n",
      "Test Data index:  0 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  1 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  2 Computed class:  setosa , True class:  setosa\n",
      "Test Data index:  3 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  4 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  5 Computed class:  versicolor , True class:  versicolor\n",
      "Test Data index:  6 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  7 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  8 Computed class:  virginica , True class:  virginica\n",
      "Test Data index:  9 Computed class:  virginica , True class:  virginica\n",
      "weighted majority vote k = 10 , Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# iris 데이터를 받아온다.\n",
    "iris=load_iris()\n",
    "#data size 150개 (feature 4개)\n",
    "X=iris.data \n",
    "# 결과 값\n",
    "y=iris.target\n",
    "# 결과 (꽃의 이름)\n",
    "y_name=iris.target_names\n",
    "\n",
    "#train data(140개), test data(10개) 분리시키자\n",
    "num=14\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "for i in range(len(X)):\n",
    "    if i==num:\n",
    "        X_test.append(X[i])\n",
    "        num+=15\n",
    "    else:\n",
    "        X_train.append(X[i])\n",
    "\n",
    "num=14\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "for i in range(len(y)):\n",
    "    if i==num:\n",
    "        y_test.append(y[i])\n",
    "        num+=15\n",
    "    else:\n",
    "        y_train.append(y[i])\n",
    "\n",
    "# KNN 분류기 객체를 만든다.\n",
    "KNN_classifier = KNN_class(X_train,y_train)\n",
    "\n",
    "# k가 3일때, 5일때, 10일때 \n",
    "k_num=[3,5,10]\n",
    "\n",
    "for k in k_num:\n",
    "    print(\"========================== k is\",k,\"==========================\")\n",
    "    for j in range(2):\n",
    "        if j ==0:\n",
    "            print(\"====================== majority vote ======================\")\n",
    "        else :\n",
    "            print(\"=================== weighted majority vote ===================\")\n",
    "        accuracy=0\n",
    "        for i in range(len(X_test)):\n",
    "            # 차례로 거리가 가까운 순으로 index 배열, 주어진 데이터와 가까운 것의 거리 배열을 나타낸다.\n",
    "            sorted_index,sorted_distance=KNN_classifier.find_nearest_neighbors(X_test[i], k)\n",
    "            if j==0:\n",
    "                # majority vote\n",
    "                predict_iris=KNN_classifier.majority_vote(sorted_index,k)         \n",
    "            else:\n",
    "                # weighted majority vote \n",
    "                predict_iris=KNN_classifier.weighted_majority_vote(sorted_index,sorted_distance,k)          \n",
    "            # 실제 데이터 값과 같은지 확인한다.\n",
    "            print(\"Test Data index: \",i,\"Computed class: \",y_name[predict_iris],\", True class: \",y_name[y_test[i]])\n",
    "            # 실제 데이터 값과 같으면 accuracy를 하나 올려준다.\n",
    "            if y_name[predict_iris] == y_name[y_test[i]]:\n",
    "                accuracy+=1\n",
    "        # accuracy를 출력하자        \n",
    "        if j==0:\n",
    "            print(\"majority vote k =\",k,\", Accuracy :\" ,accuracy/len(X_test))\n",
    "        else:\n",
    "            print(\"weighted majority vote k =\",k,\", Accuracy :\" ,accuracy/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
